<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yanjiang Guo</title>

    <meta name="author" content="Yanjiang Guo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:top">
                <p class="name" style="text-align: center;">
                  Yanjiang Guo
                </p>
                <p> Hi! I am a third-year PhD student majoring in computer science at <a href="https://iiis.tsinghua.edu.cn/">IIIS, Tsinghua University</a>, advised by Prof. <a href="https://people.iiis.tsinghua.edu.cn/~jychen/">Jianyu Chen</a>.
                Previously, I obtained my bachelor's degree from <a href="https://www.ee.tsinghua.edu.cn/">Dept. of EE, Tsinghua University</a> in 2022.
                I have also spent time at <a href="https://www.tencent.com">Tencent</a>, <a href="https://www.sensetime.com/cn">SenseTime</a>, <a href="https://www.robotera.com/en/">RobotEra</a> and <a href="https://sqz.ac.cn">Shanghai Qi Zhi Institute</a> as interns.
                <p>
        
                My research focuses on <strong>Embodied AI and Generative Models</strong>, with a particular emphasis on <strong>training robot foundation models</strong> capable of performing a wide range of tasks in our daily lifes. I believe that co-training with internet data and leveraging pre-trained generative models (e.g., VLM, video diffusion model, etc.) are crucial for developing effective generalist robot policies.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yanjiangguo666@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=rBeZZPMAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/GYanjiang">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Robert-gyj">Github</a>
                </p>
                
                <p>
                  <em>"Set your course by the stars, not by the lights of passing ships."</em>
                </p>
                
                <p>
                  <strong>Honors and Awards:</strong>
                  <br>[2024.07] RSS 2024<font color="red"><strong> Best Paper Award Finalists</strong></font>.
                  <br>[2022.06] Outstanding Graduates of Tsinghua University (Top 10%).
                  <br>[2017.11] 34th Chinese Physics Olympiad (CPhO), Silver Medal.

                </p>

                <!-- <p>
                  <strong>Contact</strong>
                  <br>[2024.07] RSS 2024<font color="red"><strong> Best Paper Award Finalists</strong></font>.
                  <br>[2022.06] Outstanding Graduates of Tsinghua (Top 10%).
                  <br>[2017.11] 34th Chinese Physics Olympiad (CPhO), Silver Metal.
                </p> -->

              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/gyj0.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/gyj0.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Honors and Awards</h2>
                <p>
                  <br><strong>[2024.07] RSS 2024<font color="red"><strong> Best Paper Award Finalists.</strong></font>
                  <br>
                  <br><strong>[2022.06] Outstanding Graduates of Tsinghua (Top 10%).</strong>
                  <br>
                  <br><strong>[2017.11] 34th Chinese Physics Olympiad (CPhO), Silver Metal.</strong>
                </p>
              </td>
            </tr>
          </tbody></table> -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px;width:100%;vertical-align:top">
                <h2>Selected Publications</h2>
                <p>
                Papers related to <span class="highlight">Robotic Foundation Model</span> training are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
              <td style="padding:10px;width:35%;vertical-align:top">
                <div class="one" style="width: 100%;">
                  <div class="two" id='nuvo_image' style="width: 100%;"><video  width=100% muted autoplay loop>
                  <source src="images/upvla.jpg">
                  Your browser does not support the video tag.
                  </video></div>
                  <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
                  <img src='images/upvla.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function nuvo_start() {
                    document.getElementById('nuvo_image').style.opacity = "1";
                  }
        
                  function nuvo_stop() {
                    document.getElementById('nuvo_image').style.opacity = "0";
                  }
                  nuvo_stop()
                </script>
              </td>
              <td style="padding:10px;width:65%;vertical-align:top">
                <a href="https://arxiv.org/abs/2501.18867">
                  <span class="papertitle">UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent</span>
                </a>
                <br>
                Jianke Zhang*, <strong>Yanjiang Guo*</strong>, Yucheng Hu*, Xiaoyu Chen, Jianyu Chen
        
                <br>
                <strong><em>Arxiv</em>, 2025</strong>
                <br>
                <a href="https://arxiv.org/abs/2501.18867">arXiv</a>

                <p></p>
                <span class="highlight">VLA Robotic Foundation Model.</span>
                <br>
                We incoperate both multi-modal understanding (MMU) and future prediction into VLA model, enhancing both high-level semantic knowledge and low-level visual dynamics.
                  
              </td>
            </tr>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:10px;width:35%;vertical-align:top">
        <div class="one" style="width: 100%;">
          <div class="two" id='nuvo_image' style="width: 100%;"><video  width=100% muted autoplay loop>
          <source src="images/vpp2.png">
          Your browser does not support the video tag.
          </video></div>
          <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
          <img src='images/vpp2.png' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:10px;width:65%;vertical-align:top">
        <a href="https://video-prediction-policy.github.io/">
          <span class="papertitle">Video Prediction Policy: A Generalist Robot Policy with Predictive Visual
            Representations</span>
        </a>
        <br>
        Yucheng Hu*, <strong>Yanjiang Guo*</strong>, Pengchao Wang, Xiaoyu Chen, Yen-Jen Wang, Jianke Zhang, Koushil Sreenath, Chaochao Lu, Jianyu Chen

        <br>
        <strong><em>Arxiv</em>, 2024</strong>
        <br>
        <a href="https://video-prediction-policy.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.14803">arXiv</a>
        /
        <a href="https://x.com/GYanjiang/status/1871001766457971113">twitter</a>
        /
        <a href="https://mp.weixin.qq.com/s/oxIZWyat8hqtbgwCCGLu9A">量子位</a>

        <p></p>
        <span class="highlight">Video Generation (or World Model) based Robotic Foundation Model</span>
        <br>
        We finetune a general-purpose video diffusion model into manipulation-focused video prediction model to guide policy learning. 
          <!-- Notably, our generalist policy solves over 100+ dexterous hand manipulation tasks. -->

      </td>
    </tr>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:10px;width:35%;vertical-align:top">
        <div class="one" style="width: 100%;">
          <div class="two" id='nuvo_image' style="width: 100%;"><video  width=100% muted autoplay loop>
          <source src="images/irevla.jpg">
          Your browser does not support the video tag.
          </video></div>
          <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
          <img src='images/irevla.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:10px;width:65%;vertical-align:top">
        <a href="https://arxiv.org/abs/2501.16664">
          <span class="papertitle">Improving Vision-Language-Action Model with Online Reinforcement Learning</span>
        </a>
        <br>
		    <strong>Yanjiang Guo*</strong>, Jianke Zhang*, Xiaoyu Chen*, Xiang Ji, Yen-Jen Wang, Yucheng Hu, Jianyu Chen
        <br>
        <strong><em>ICRA</em>, 2025</strong>
        <br>
        <a href="https://arxiv.org/abs/2501.16664">arXiv</a>
        /
        <a href="https://x.com/RoboReading/status/1884473082053599459">twitter1</a>
        /
        <a href="https://x.com/chris_j_paxton/status/1887525625042248018">twitter2</a>
        <p></p>
        <span class="highlight">VLA Robotic Foundation Model.</span>
        <br>
          We make some initial exploration on leveraging online RL to improve the VLA model! We notice that online RL for VLA can be extremely unstable and thus we adopted a iterative approach.
          

      </td>
    </tr>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:10px;width:35%;vertical-align:top">
        <div class="one" style="width: 100%;">
          <div class="two" id='nuvo_image' style="width: 100%;"><video  width=100% muted autoplay loop>
          <source src="images/PAD2.png">
          Your browser does not support the video tag.
          </video></div>
          <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
          <img src='images/PAD2.png' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:10px;width:65%;vertical-align:top">
        <a href="https://sites.google.com/view/pad-paper">
          <span class="papertitle">Prediction with Action: Visual Policy Learning via Joint Denoising Process</span>
        </a>
        <br>
		    <strong>Yanjiang Guo*</strong>, Yucheng Hu*, Jianke Zhang, Yen-Jen Wang, Xiaoyu Chen, Chaochao Lu#, Jianyu Chen#
        <br>
        <strong><em>NeurIPS</em>, 2024</strong>
        <br>
        <a href="https://sites.google.com/view/pad-paper">project page</a>
        /
        <a href="https://github.com/Robert-gyj/Prediction_with_Action">code</a>
        /
        <a href="https://arxiv.org/pdf/2411.18179">arXiv</a>

        <p></p>
        <span class="highlight">Video Generation (or World Model) based Robotic Foundation Model</span>
        <br>
        We jointly predict future images and robot actions in a unified DiT network, transfering physical knowledge from internet video data to robots.
          
        </p>
      </td>
    </tr>
    <!-- <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()">
      <td style="padding:10px;width:30%;vertical-align:top">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.jpg" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="170">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }

          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:10px;width:70%;vertical-align:top">
        <a href="https://cat3d.github.io/">
			<span class="papertitle">Improving Vision-Language-Action Model with Online Reinforcement Learning</span>
        </a>
        <br>
				<strong>Yanjiang Guo*</strong>, Jianke Zhang*, Xiaoyu Chen*, Xiang Ji, Yen-Jen Wang, Yucheng Hu, Jianyu Chen

        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://cat3d.github.io/">code</a>
        /
        <a href="https://arxiv.org/abs/2305.10314">arXiv</a>
        <p></p>
        <p>
          Improving Vision-Language-Action Model with Online Reinforcement Learning.
        </p>
      </td>
    </tr> -->
    <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:10px;width:35%;vertical-align:top">
        <div class="one" style="width: 100%;">
          <div class="two" id='bog_image' style="width: 100%;"><video  width=100% muted autoplay loop>
            <source src="images/hirt.png">
            Your browser does not support the video tag.
            </video></div>
            <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
            <img src='images/hirt.png' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('bog_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('bog_image').style.opacity = "0";
          }
          bog_stop()
        </script>
      </td>
      <td style="padding:10px;width:65%;vertical-align:top">
        <a href="https://arxiv.org/pdf/2410.05273">
          <span class="papertitle">HiRT: Enhancing Robotic Control with Hierarchical Robot Transformers</span>
        </a>
        <br>
				Jianke Zhang*, <strong>Yanjiang Guo*</strong>, Xiaoyu Chen, Yen-Jen Wang, Yucheng Hu, Chengming Shi, Jianyu Chen	
        <br>
        <strong><em>CoRL</em>, 2024</strong>
        <br>
        <a href="https://arxiv.org/pdf/2410.05273">arXiv</a>
        /
        <a href="https://x.com/GYanjiang/status/1892594610750300488">twitter</a>
        /
        <a href="https://mp.weixin.qq.com/s/kytaMLu_-6Ojlva_8N28Ng">机器之心</a>
        <p></p>
        <span class="highlight">VLA Robotic Foundation Model</span>
        <br>
        We finetune pretrained VLM into VLA models with hierarchical transformers, keeping the generalization ability but also much higher control frequency.
          
        </p>
      </td>
    </tr>
    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:10px;width:35%;vertical-align:top">
        <div class="one" style="width: 100%;">
          <div class="two" id='smerf_image' style="width: 100%;"><video  width=100% muted autoplay loop>
            <source src="images/DWL.png">
            Your browser does not support the video tag.
            </video></div>
            <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
            <img src='images/DWL.png' width=100%>
        </div>
        <script type="text/javascript">
          function smerf_start() {
            document.getElementById('smerf_image').style.opacity = "1";
          }

          function smerf_stop() {
            document.getElementById('smerf_image').style.opacity = "0";
          }
          smerf_stop()
        </script>
      </td>
      <td style="padding:10px;width:65%;vertical-align:top">
        <a href="https://sites.google.com/view/humanoid-gym/">
          <span class="papertitle">Advancing Humanoid Locomotion: Mastering Challenging Terrains with Denoising World Model Learning</span>
        </a>
        <br>
        Xinyang Gu*, Yen-Jen Wang*, Xiang Zhu*, Chengming Shi*, <strong>Yanjiang Guo</strong>, Yichen Liu, Jianyu Chen
        <br>
        <strong><em>RSS</em>, 2024</strong> &nbsp <font color="red"><strong>(Best Paper Award Finalists)</strong></font>
        <br>
        <a href="https://sites.google.com/view/humanoid-gym/">project page</a>
        /
        <a href="https://github.com/roboterax/humanoid-gym">code</a>
        /
        <a href="https://enriquecoronadozu.github.io/rssproceedings2024/rss20/p058.pdf">arXiv</a>
        /
        <a href="https://mp.weixin.qq.com/s/5lY5Fj82lrRWikn6LNceWg">机器之心</a>
        <p></p>
        <p>
        We train humanoid robot to master challenging terrains such as stairs, slopes, and snow grounds with zero-shot sim2real transfer.
        </p>
      </td>
    </tr>
    <tr onmouseout="internerf_stop()" onmouseover="internerf_start()">
      <td style="padding:10px;width:35%;vertical-align:top">
        <div class="one" style="width: 100%;">
          <div class="two" id='internerf_image' style="width: 100%;"><video  width=100% muted autoplay loop>
            <source src="images/doremi_clip.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <!-- <video src='images/doremi_clip.mp4' type="video/mp4" width=100%></video> -->
            <img src='images/doremi.png' width=100%>
        </div>
        <script type="text/javascript">
          function internerf_start() {
            document.getElementById('internerf_image').style.opacity = "1";
          }

          function internerf_stop() {
            document.getElementById('internerf_image').style.opacity = "0";
          }
          internerf_stop()
        </script>
      </td>
      <td style="padding:10px;width:65%;vertical-align:top">
        <a href="https://sites.google.com/view/doremi-paper">
          <span class="papertitle">DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment</span>
        </a>
        <br>
        <strong>Yanjiang Guo*</strong> , Yen-Jen Wang*, Lihan Zha*, Jianyu Chen
        <br>
        <strong><em>IROS</em>, 2024</strong>
        <br>
        <a href="https://sites.google.com/view/doremi-paper">project page</a>
        <!-- /
        <a href="https://sites.google.com/view/doremi-paper">code</a> -->
        /
        <a href="https://arxiv.org/pdf/2307.00329">arXiv</a>
        <p></p>
        <p>
          We leverage LLM to pefrom both planning and monitoring, with a fine-tuned VLM as detector.
        </p>
      </td>
    </tr>

          </tbody></table>

          <p></p>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Other Publications</h2>
                <p>
                  <a href="https://arxiv.org/pdf/2306.17411">
                    <span class="papertitle">Decentralized Motor Skill Learning for Complex Robotic Systems</span>
                  </a>
                  <br><strong>Yanjiang Guo*</strong>, Zheyuan Jiang*, Yen-Jen Wang, Jingyue Gao, Jianyu Chen
                  <br><em><strong>RA-L, 2023 (with ICRA 2024) </strong></em>
                  <p></p>
                  <a href="hhttps://arxiv.org/pdf/2210.00350">
                    <span class="papertitle">Zero-shot policy transfer with disentangled task representation of meta-reinforcement learning</span>
                  </a>
                  <br>Zheng Wu, Yichen Xie, Wenzhao Lian, Changhao Wang, <strong>Yanjiang Guo</strong>, Jianyu Chen, Stefan Schaal, Masayoshi Tomizuka
                  <br><em><strong>ICRA,2023</strong></em>
                  <p></p>
                  <a href="https://proceedings.mlr.press/v205/guo23a/guo23a.pdf"> 
                    <span class="papertitle">Reinforcement learning with Demonstrations from Mismatched Task under Sparse Reward</span>
                  </a>
                  <br><strong>Yanjiang Guo</strong>, Jingyue Gao, Zheng Wu, Chengming Shi, Jianyu Chen
                  <br><em><strong>CoRL, 2022</strong></em>
                  <p></p>
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Honors and Awards</h2>
                <p>
                  <br>RSS Outstanding Paper Award Finalists, 2024.
                  <br>Outstanding Graduates of Tsinghua (Top 10%), 2022.
                  <br>34th Chinese Physics Olympiad (CPhO), Silver Metal, 2017.
                </p>
              </td>
            </tr>
          </tbody></table> -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
